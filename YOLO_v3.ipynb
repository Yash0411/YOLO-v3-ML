{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjSYqOC1GFsDnIDhXWLJht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash0411/YOLO-v3-ML/blob/master/YOLO_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA6qJhCMAZwT",
        "colab_type": "text"
      },
      "source": [
        "#YOLO V3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KXYbTF5AfU0",
        "colab_type": "text"
      },
      "source": [
        "#Import Modules and libraries\n",
        "\n",
        "\n",
        "\n",
        "*   yolo_utils contains functions for reading the prediction classes from coco_classes.txt.\n",
        "*   darknetmodel consist of the darknet model used.\n",
        "*   utils is a file consisting functions for drawing boxes, iou, load images, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkdNzAolfEuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model, Model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from yolo_utils import read_classes, read_anchors\n",
        "from darknetmodel import _conv_block,make_yolov3_model,WeightReader\n",
        "from utils import BoundBox,_sigmoid,decode_netout,correct_yolo_boxes,_interval_overlap,bbox_iou,do_nms,load_image_pixels,get_boxes,generate_colors,draw_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdMEwnOFBXUn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Get the labels.\n",
        "2.   Define the anchors.\n",
        "3.   Declare shape for images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZYO4xuZFJQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = read_classes(\"/content/coco_classes.txt\")\n",
        "\n",
        "# Parameters used in the Dataset, on which YOLOv3 was pretrained\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "image_shape = (720., 1280.)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoHIe72SBzsH",
        "colab_type": "text"
      },
      "source": [
        "# Download the YOLOv3 weights\n",
        "\n",
        "Download weights from https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_71lIJSmFEvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_tFxfTaCEzZ",
        "colab_type": "text"
      },
      "source": [
        "# Convert the .weights to h5 file\n",
        "\n",
        "convert.py converts the weights from .weights file to hdf5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP41lZXhFGvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python convert.py yolov3.cfg yolov3.weights /content/yolo.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcgNM8-5CdXH",
        "colab_type": "text"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJajiAPjp6dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load yolov3 model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/yolo.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o720eJWKCh-h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Generation of different colors for number of labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AxIHZ25p8sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the expected input shape for the model\n",
        "WIDTH, HEIGHT = 416, 416\n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.3\n",
        "\n",
        "# Generate Colors\n",
        "colors = generate_colors(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9td6SwKuDDZO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Declare test Directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7D0rmnTp-pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "images = os.listdir('/content/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c23Rgg2IDaOu",
        "colab_type": "text"
      },
      "source": [
        "# Predict from test Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KKCZd6XqCF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "# define the expected input shape for the model\n",
        "WIDTH, HEIGHT = 416, 416\n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.3\n",
        "\n",
        "for file in images:\n",
        "    photo_filename =  '/content/test/' + file\n",
        "    \n",
        "    # load picture with old dimensions\n",
        "    image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n",
        "    \n",
        "    # Predict image\n",
        "    yhat = model.predict(image)\n",
        "    \n",
        "    # Create boxes\n",
        "    boxes = list()\n",
        "    for i in range(len(yhat)):\n",
        "        # decode the output of the network\n",
        "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)\n",
        "\n",
        "    # correct the sizes of the bounding boxes for the shape of the image\n",
        "    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    do_nms(boxes, 0.5)\n",
        "\n",
        "    # define the labels (Filtered only the ones relevant for this task, which were used in pretraining the YOLOv3 model)\n",
        "    labels = read_classes(\"/content/coco_classes.txt\")\n",
        "    \n",
        "    # get the details of the detected objects\n",
        "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "    # summarize what we found\n",
        "    for i in range(len(v_boxes)):\n",
        "\n",
        "        print(v_labels[i], v_scores[i])\n",
        "\n",
        "    \n",
        "    # draw what we found\n",
        "    draw_boxes(photo_filename, v_boxes, v_labels, v_scores, labels, colors)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}